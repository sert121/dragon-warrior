{"step": "query_llm.tokens", "input_tokens": 761, "output_tokens": 64}
{"step": "query_llm.tokens", "input_tokens": 788, "output_tokens": 107}
{"step": "query_llm.tokens", "input_tokens": 816, "output_tokens": 113}
{"step": "query_llm.tokens", "input_tokens": 840, "output_tokens": 78}
{"step": "query_llm.tokens", "input_tokens": 868, "output_tokens": 82}
{"step": "query_llm.tokens", "input_tokens": 894, "output_tokens": 3047}
{"step": "query_llm.tokens", "input_tokens": 911, "output_tokens": 113}
{"step": "query_llm.tokens", "input_tokens": 940, "output_tokens": 811}
{"step": "query_llm.tokens", "input_tokens": 977, "output_tokens": 85}
{"step": "query_llm.tokens", "input_tokens": 1003, "output_tokens": 1311}
{"step": "query_llm.tokens", "input_tokens": 1032, "output_tokens": 489}
{"step": "query_llm.tokens", "input_tokens": 1055, "output_tokens": 186}
{"step": "query_llm.tokens", "input_tokens": 1080, "output_tokens": 257}
{"step": "query_llm.tokens", "input_tokens": 1097, "output_tokens": 119}
{"step": "query_llm.tokens", "input_tokens": 1123, "output_tokens": 2279}
{"step": "query_llm.tokens", "input_tokens": 1140, "output_tokens": 712}
{"step": "query_llm.tokens", "input_tokens": 1157, "output_tokens": 200}
{"step": "query_llm.tokens", "input_tokens": 1184, "output_tokens": 134}
{"step": "query_llm.tokens", "input_tokens": 1210, "output_tokens": 289}
{"step": "query_llm.tokens", "input_tokens": 1238, "output_tokens": 164}
{"step": "query_llm.tokens", "input_tokens": 1262, "output_tokens": 169}
{"step": "query_llm.tokens", "input_tokens": 1279, "output_tokens": 197}
{"step": "query_llm.tokens", "input_tokens": 1296, "output_tokens": 106}
{"step": "query_llm.tokens", "input_tokens": 1320, "output_tokens": 172}
{"step": "query_llm.tokens", "input_tokens": 1355, "output_tokens": 178}
{"step": "query_llm.tokens", "input_tokens": 1389, "output_tokens": 1474}
{"step": "query_llm.tokens", "input_tokens": 1412, "output_tokens": 243}
{"step": "query_llm.tokens", "input_tokens": 1456, "output_tokens": 95}
{"step": "query_llm.tokens", "input_tokens": 1485, "output_tokens": 379}
